<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Kawaii Face</title>
  <style>
    body {
      background: #fff0f6;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
    }

    .face {
      width: 300px;
      height: 300px;
      background: #ffe3ec;
      border-radius: 50%;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      position: relative;
      box-shadow: 0 0 30px rgba(0,0,0,0.1);
    }

    .eyes {
      display: flex;
      gap: 60px;
      margin-bottom: 20px;
    }

    .eye {
      width: 40px;
      height: 40px;
      background: #000;
      border-radius: 50%;
    }

    .eye.closed {
      height: 6px;
      border-radius: 3px;
      background: #000;
    }

    .mouth {
      width: 60px;
      height: 30px;
      background: #d6336c;
      border-radius: 0 0 30px 30px;
      transition: height 0.1s ease;
    }

    .mouth.open {
      height: 70px;
    }
  </style>
</head>
<body>
  <div class="face">
    <div class="eyes">
      <div class="eye" id="eyeL"></div>
      <div class="eye" id="eyeR"></div>
    </div>
    <div class="mouth" id="mouth"></div>
  </div>

  <script>
    // Blinking
    const leftEye = document.getElementById('eyeL');
    const rightEye = document.getElementById('eyeR');

    function blink() {
      leftEye.classList.add('closed');
      rightEye.classList.add('closed');
      setTimeout(() => {
        leftEye.classList.remove('closed');
        rightEye.classList.remove('closed');
      }, 150);
    }

    setInterval(() => {
      if (Math.random() > 0.5) blink();
    }, 3000);

    // Mic Input
    const mouth = document.getElementById('mouth');

    async function startMic() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioCtx.createMediaStreamSource(stream);
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 512;

        source.connect(analyser);

        const dataArray = new Uint8Array(analyser.frequencyBinCount);

        function update() {
          analyser.getByteFrequencyData(dataArray);
          const volume = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

          if (volume > 30) {
            mouth.classList.add('open');
          } else {
            mouth.classList.remove('open');
          }

          requestAnimationFrame(update);
        }

        update();
      } catch (err) {
        alert('Mic access is needed to animate the mouth!');
        console.error(err);
      }
    }

    startMic();
  </script>
</body>
</html>
